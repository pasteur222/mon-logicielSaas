import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from "npm:@supabase/supabase-js@2"
import { createGroqClient, getSystemGroqClient } from "../_shared/groq-client.ts"

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
  "Access-Control-Allow-Headers": "Content-Type, Authorization",
}

interface ProcessingLog {
  step: string
  timestamp: string
  data: any
  success: boolean
  error?: string
}

interface ContentAnalysis {
  contentType: 'text' | 'math' | 'science' | 'mixed' | 'unknown'
  subject: string
  confidence: number
  hasEquations: boolean
  hasText: boolean
  hasHandwriting: boolean
  textContent?: string
  reasoning: string
}

interface UserContextAnalysis {
  intent: 'text_help' | 'math_help' | 'science_help' | 'general_help' | 'unknown'
  keywords: string[]
  confidence: number
  reasoning: string
}

interface ChatbotRequest {
  from?: string // Phone number for WhatsApp
  webUserId?: string // UUID for web users
  sessionId?: string // Session tracking
  source?: 'whatsapp' | 'web'
  text?: string
  imageUrl?: string
  chatbotType?: string
  userAgent?: string
}

serve(async (req: Request) => {
  const processingLogs: ProcessingLog[] = []
  
  const addLog = (step: string, data: any, success: boolean = true, error?: string) => {
    processingLogs.push({
      step,
      timestamp: new Date().toISOString(),
      data,
      success,
      error
    })
  }

  if (req.method === "OPTIONS") {
    return new Response(null, {
      status: 200,
      headers: corsHeaders,
    })
  }

  try {
    addLog('REQUEST_START', { method: req.method, url: req.url })

    const requestData: ChatbotRequest = await req.json()
    addLog('MESSAGE_PARSED', { 
      hasFrom: !!requestData.from,
      hasWebUserId: !!requestData.webUserId,
      hasText: !!requestData.text,
      hasImageUrl: !!requestData.imageUrl,
      source: requestData.source,
      chatbotType: requestData.chatbotType 
    })

    // Validate request data based on source
    const { from, webUserId, sessionId, source = 'whatsapp', text, imageUrl, chatbotType, userAgent } = requestData

    // Determine user identifier based on source
    let userIdentifier: string
    if (source === 'web') {
      if (!webUserId) {
        addLog('VALIDATION_ERROR', { source, webUserId }, false, 'Missing webUserId for web source')
        return new Response(
          JSON.stringify({ 
            error: 'Missing required field: webUserId for web source',
            processingLogs 
          }),
          {
            status: 400,
            headers: { 'Content-Type': 'application/json', ...corsHeaders },
          }
        )
      }
      userIdentifier = webUserId
    } else {
      if (!from) {
        addLog('VALIDATION_ERROR', { source, from }, false, 'Missing from field for WhatsApp source')
        return new Response(
          JSON.stringify({ 
            error: 'Missing required field: from for WhatsApp source',
            processingLogs 
          }),
          {
            status: 400,
            headers: { 'Content-Type': 'application/json', ...corsHeaders },
          }
        )
      }
      userIdentifier = from
    }

    if (!text && !imageUrl) {
      addLog('VALIDATION_ERROR', { hasText: !!text, hasImageUrl: !!imageUrl }, false, 'Missing text or imageUrl')
      return new Response(
        JSON.stringify({ 
          error: 'Missing required fields: text or imageUrl',
          processingLogs 
        }),
        {
          status: 400,
          headers: { 'Content-Type': 'application/json', ...corsHeaders },
        }
      )
    }

    // Route to appropriate chatbot handler
    let response: string
    let whatsappSent = false

    switch (chatbotType) {
      case 'education':
        addLog('EDUCATION_START', { userIdentifier, source, messageLength: text?.length || 0 })
        response = await handleEducationMessage(userIdentifier, source, text, imageUrl, sessionId, userAgent, processingLogs, addLog)
        break
      case 'client':
        addLog('CLIENT_START', { userIdentifier, source })
        response = await handleClientMessage(userIdentifier, source, text, sessionId, userAgent, processingLogs, addLog)
        break
      case 'quiz':
        addLog('QUIZ_START', { userIdentifier, source })
        response = await handleQuizMessage(userIdentifier, source, text, sessionId, userAgent, processingLogs, addLog)
        break
      default:
        addLog('DEFAULT_EDUCATION', { chatbotType })
        response = await handleEducationMessage(userIdentifier, source, text, imageUrl, sessionId, userAgent, processingLogs, addLog)
    }

    addLog('PROCESSING_COMPLETE', { 
      responseLength: response.length,
      whatsappSent,
      chatbotType,
      source 
    })

    return new Response(
      JSON.stringify({ 
        success: true, 
        response,
        chatbotType,
        whatsappSent,
        source,
        processingLogs
      }),
      {
        headers: { 'Content-Type': 'application/json', ...corsHeaders },
      }
    )
  } catch (error) {
    addLog('GLOBAL_ERROR', { error: error.message }, false, error.message)
    console.error('‚ùå [API-CHATBOT] Global error:', error)
    
    return new Response(
      JSON.stringify({ 
        success: false, 
        error: error.message,
        processingLogs
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json', ...corsHeaders },
      }
    )
  }
})

// Enhanced Groq API call with retry mechanism
async function callGroqWithRetry(
  groq: any,
  messages: any[],
  model: string,
  temperature: number = 0.7,
  maxTokens: number = 2048,
  maxRetries: number = 3,
  addLog: Function
): Promise<any> {
  let lastError: Error | null = null
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      addLog('GROQ_API_CALL', { attempt, model, messageCount: messages.length })
      
      const completion = await groq.chat.completions.create({
        messages,
        model,
        temperature,
        max_tokens: maxTokens,
      })
      
      addLog('GROQ_API_SUCCESS', { attempt, responseLength: completion.choices[0]?.message?.content?.length || 0 })
      return completion
      
    } catch (error) {
      lastError = error
      addLog('GROQ_API_ERROR', { attempt, error: error.message }, false, error.message)
      
      // Check if it's a rate limit error
      if (error.message?.includes('429') || error.message?.includes('rate limit')) {
        if (attempt < maxRetries) {
          const delay = Math.pow(2, attempt) * 1000 // Exponential backoff: 2s, 4s, 8s
          addLog('GROQ_RETRY_DELAY', { attempt, delay })
          await new Promise(resolve => setTimeout(resolve, delay))
          continue
        }
      }
      
      // Check if it's a deprecated model error
      if (error.message?.includes('decommissioned') || error.message?.includes('deprecated')) {
        if (model !== 'llama3-70b-8192') {
          addLog('GROQ_MODEL_FALLBACK', { originalModel: model, fallbackModel: 'llama3-70b-8192' })
          // Retry with the default model
          try {
            const completion = await groq.chat.completions.create({
              messages,
              model: 'llama3-70b-8192',
              temperature,
              max_tokens: maxTokens,
            })
            addLog('GROQ_FALLBACK_SUCCESS', { model: 'llama3-70b-8192' })
            return completion
          } catch (fallbackError) {
            addLog('GROQ_FALLBACK_ERROR', { error: fallbackError.message }, false)
            throw fallbackError
          }
        }
      }
      
      // For other errors, don't retry
      if (!error.message?.includes('429') && !error.message?.includes('rate limit')) {
        throw error
      }
    }
  }
  
  // All retries exhausted
  addLog('GROQ_RETRIES_EXHAUSTED', { maxRetries }, false, lastError?.message)
  throw lastError || new Error('Groq API call failed after retries')
}

async function handleEducationMessage(
  userIdentifier: string,
  source: string,
  text: string | undefined,
  imageUrl: string | undefined,
  sessionId: string | undefined,
  userAgent: string | undefined,
  processingLogs: ProcessingLog[],
  addLog: Function
): Promise<string> {
  try {
    addLog('IMAGE_CHECK', { hasImage: !!imageUrl, hasText: !!text, source })

    const supabaseUrl = Deno.env.get('SUPABASE_URL')
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
    
    if (!supabaseUrl || !supabaseServiceKey) {
      throw new Error('Missing Supabase environment variables')
    }
    
    const supabase = createClient(supabaseUrl, supabaseServiceKey)

    // Handle different sources
    let student: any = null
    if (source === 'whatsapp') {
      // Get or create student profile for WhatsApp users
      student = await getOrCreateStudentProfile(userIdentifier, supabase, addLog)
      addLog('STUDENT_PROFILE', { studentId: student.id, level: student.level, source })

      // Create or get active education session
      const session = await getOrCreateEducationSession(student.id, supabase, addLog)
      addLog('EDUCATION_SESSION', { sessionId: session.id, source })
    } else {
      // For web users, create a minimal profile for processing
      student = {
        id: userIdentifier,
        phone_number: userIdentifier,
        level: '3√®me', // Default level for web users
        user_id: null,
        source: 'web'
      }
      addLog('WEB_USER_PROFILE', { webUserId: userIdentifier, source })
    }

    // Get Groq configuration
    const groqConfig = await getGroqConfigForEducation(student, supabase, addLog)
    addLog('GROQ_CONFIG', { hasApiKey: !!groqConfig.apiKey, model: groqConfig.model, source })

    // Enhanced response generation with robust error handling
    let response: string
    try {
      addLog('ENHANCED_RESPONSE_START', { hasImage: !!imageUrl, source })
      response = await generateEnhancedEducationalResponse(
        text, 
        imageUrl, 
        student, 
        groqConfig, 
        addLog
      )
      addLog('ENHANCED_RESPONSE_SUCCESS', { responseLength: response.length, source })
    } catch (enhancedError) {
      addLog('ENHANCED_RESPONSE_ERROR', { error: enhancedError.message }, false, enhancedError.message)
      console.error('‚ùå [EDUCATION] Enhanced response failed:', enhancedError)
      
      // Robust fallback to basic response
      try {
        addLog('FALLBACK_RESPONSE_START', { source })
        response = await generateBasicEducationalResponse(text || 'Question sans texte', student, groqConfig, addLog)
        addLog('FALLBACK_RESPONSE_SUCCESS', { responseLength: response.length, source })
      } catch (fallbackError) {
        addLog('FALLBACK_RESPONSE_ERROR', { error: fallbackError.message }, false, fallbackError.message)
        console.error('‚ùå [EDUCATION] Fallback response also failed:', fallbackError)
        
        // Final fallback - contextual error message
        if (imageUrl) {
          response = "Je rencontre des difficult√©s pour analyser cette image. Pourriez-vous me d√©crire ce que vous souhaitez que je vous aide √† comprendre ? Par exemple : 'Aidez-moi avec cette lettre' ou 'Expliquez-moi ce probl√®me de math√©matiques'."
        } else {
          response = "Je rencontre des difficult√©s techniques temporaires. Pourriez-vous reformuler votre question ou √™tre plus sp√©cifique sur le type d'aide dont vous avez besoin ?"
        }
        addLog('FINAL_FALLBACK_USED', { responseLength: response.length, source })
      }
    }

    // Save the conversation with proper source handling
    await saveEducationConversation(userIdentifier, source, text, response, sessionId, userAgent, supabase, addLog)
    
    addLog('RESPONSE_GENERATED', { 
      responseLength: response.length,
      hasImage: !!imageUrl,
      source 
    })

    return response

  } catch (error) {
    addLog('EDUCATION_ERROR', { error: error.message, source }, false, error.message)
    console.error('‚ùå [EDUCATION] Error:', error)
    
    // Return contextual error message based on source
    if (source === 'web') {
      return "Je rencontre des difficult√©s techniques. Veuillez actualiser la page et r√©essayer."
    } else {
      return "D√©sol√©, je rencontre des difficult√©s techniques. Veuillez r√©essayer plus tard."
    }
  }
}

async function generateEnhancedEducationalResponse(
  text: string | undefined,
  imageUrl: string | undefined,
  student: any,
  groqConfig: any,
  addLog: Function
): Promise<string> {
  try {
    const groq = await createGroqClient(groqConfig.userId)

    if (imageUrl) {
      addLog('IMAGE_PROCESSING_START', { imageUrl: imageUrl.substring(0, 50) + '...' })
      
      // Step 1: Analyze user context from text message
      let userContext: UserContextAnalysis
      try {
        userContext = await analyzeUserContext(text || '', groq, addLog)
        addLog('USER_CONTEXT_ANALYSIS', { 
          intent: userContext.intent, 
          confidence: userContext.confidence 
        })
      } catch (contextError) {
        addLog('USER_CONTEXT_ERROR', { error: contextError.message }, false)
        // Use safe defaults if context analysis fails
        userContext = {
          intent: 'unknown',
          keywords: [],
          confidence: 0.3,
          reasoning: 'Context analysis failed, using defaults'
        }
      }

      // Step 2: Analyze image content with context-aware prompting
      let contentAnalysis: ContentAnalysis
      try {
        contentAnalysis = await analyzeImageContent(imageUrl, userContext, groq, addLog)
        addLog('IMAGE_CONTENT_ANALYSIS', { 
          contentType: contentAnalysis.contentType,
          subject: contentAnalysis.subject,
          confidence: contentAnalysis.confidence 
        })
      } catch (analysisError) {
        addLog('IMAGE_ANALYSIS_ERROR', { error: analysisError.message }, false)
        // Use safe defaults if image analysis fails
        contentAnalysis = {
          contentType: 'unknown',
          subject: 'g√©n√©ral',
          confidence: 0.3,
          hasEquations: false,
          hasText: true,
          hasHandwriting: false,
          reasoning: 'Image analysis failed, using safe defaults'
        }
      }

      // Step 3: Generate response with content-specific prompting
      let response: string
      try {
        response = await generateContextualImageResponse(
          text || '', 
          imageUrl, 
          userContext, 
          contentAnalysis, 
          student, 
          groq, 
          addLog
        )
      } catch (responseError) {
        addLog('CONTEXTUAL_RESPONSE_ERROR', { error: responseError.message }, false)
        // Fallback to basic image response
        response = await generateBasicImageResponse(text || '', imageUrl, student, groq, addLog)
      }

      // Step 4: Validate response for hallucinations
      try {
        const validatedResponse = validateEducationalResponse(
          response, 
          userContext, 
          contentAnalysis, 
          text || '',
          addLog
        )
        addLog('IMAGE_PROCESSING_COMPLETE', { 
          finalResponseLength: validatedResponse.length,
          contentType: contentAnalysis.contentType 
        })
        return validatedResponse
      } catch (validationError) {
        addLog('VALIDATION_ERROR', { error: validationError.message }, false)
        // Return unvalidated response if validation fails
        return response
      }

    } else {
      addLog('TEXT_PROCESSING_START', { textLength: text?.length || 0 })
      
      // Handle text-only message with robust error handling
      let userContext: UserContextAnalysis
      try {
        userContext = await analyzeUserContext(text || '', groq, addLog)
        addLog('TEXT_CONTEXT_ANALYSIS', { 
          intent: userContext.intent, 
          confidence: userContext.confidence 
        })
      } catch (contextError) {
        addLog('TEXT_CONTEXT_ERROR', { error: contextError.message }, false)
        userContext = {
          intent: 'general_help',
          keywords: [],
          confidence: 0.5,
          reasoning: 'Context analysis failed, using general help'
        }
      }

      try {
        const completion = await callGroqWithRetry(
          groq,
          [
            {
              role: "system",
              content: generateTextSystemPrompt(student, userContext)
            },
            { role: "user", content: text || 'Question sans contenu sp√©cifique' }
          ],
          groqConfig.model,
          0.7,
          2048,
          3,
          addLog
        )

        const response = completion.choices[0]?.message?.content || 
          "Je suis d√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse appropri√©e √† votre question."

        addLog('TEXT_PROCESSING_COMPLETE', { responseLength: response.length })
        return response
      } catch (groqError) {
        addLog('TEXT_GROQ_ERROR', { error: groqError.message }, false)
        throw new Error(`Erreur lors de la g√©n√©ration de la r√©ponse: ${groqError.message}`)
      }
    }
  } catch (error) {
    addLog('ENHANCED_RESPONSE_FATAL_ERROR', { error: error.message }, false)
    throw error
  }
}

async function generateBasicImageResponse(
  text: string,
  imageUrl: string,
  student: any,
  groq: any,
  addLog: Function
): Promise<string> {
  try {
    addLog('BASIC_IMAGE_RESPONSE_START', { hasText: !!text })
    
    const completion = await callGroqWithRetry(
      groq,
      [
        {
          role: "system",
          content: `Vous √™tes un assistant √©ducatif pour les √©l√®ves de ${student.level}. 
          Analysez cette image √©ducative et aidez l'√©tudiant de mani√®re appropri√©e.
          Si vous n'√™tes pas s√ªr du contenu, demandez des clarifications.
          R√©pondez toujours en fran√ßais.`
        },
        { 
          role: "user", 
          content: [
            { type: "text", text: text || "Veuillez analyser cette image √©ducative." },
            { type: "image_url", image_url: { url: imageUrl } }
          ]
        }
      ],
      'llama3-70b-8192',
      0.7,
      1500,
      3,
      addLog
    )

    const response = completion.choices[0]?.message?.content || 
      "Je ne peux pas analyser cette image pour le moment. Pourriez-vous me d√©crire ce que vous voyez ou poser une question sp√©cifique ?"

    addLog('BASIC_IMAGE_RESPONSE_SUCCESS', { responseLength: response.length })
    return response

  } catch (error) {
    addLog('BASIC_IMAGE_RESPONSE_ERROR', { error: error.message }, false)
    return "Je rencontre des difficult√©s pour analyser cette image. Pourriez-vous me d√©crire le contenu ou poser votre question sous forme de texte ?"
  }
}

async function analyzeUserContext(text: string, groq: any, addLog: Function): Promise<UserContextAnalysis> {
  try {
    if (!text || text.trim().length === 0) {
      return {
        intent: 'unknown',
        keywords: [],
        confidence: 0.3,
        reasoning: 'Empty or missing text'
      }
    }

    const contextPrompt = `Analyze this student message to understand their intent and the type of help they need.

Message: "${text}"

Determine:
1. What type of help they're seeking (text/literature vs math vs science vs general)
2. Key indicators in their language
3. Confidence level of your assessment

Respond in JSON format:
{
  "intent": "text_help|math_help|science_help|general_help|unknown",
  "keywords": ["keyword1", "keyword2"],
  "confidence": 0.8,
  "reasoning": "explanation of your analysis"
}`

    const completion = await callGroqWithRetry(
      groq,
      [
        { role: "system", content: "You are an expert at understanding student intent from their messages." },
        { role: "user", content: contextPrompt }
      ],
      "llama3-70b-8192",
      0.1,
      300,
      2,
      addLog
    )

    const result = JSON.parse(completion.choices[0]?.message?.content || '{}')
    
    return {
      intent: result.intent || 'unknown',
      keywords: result.keywords || [],
      confidence: result.confidence || 0.5,
      reasoning: result.reasoning || 'No analysis available'
    }
  } catch (error) {
    addLog('USER_CONTEXT_ERROR', { error: error.message }, false)
    return {
      intent: 'unknown',
      keywords: [],
      confidence: 0.3,
      reasoning: 'Analysis failed, using fallback'
    }
  }
}

async function analyzeImageContent(
  imageUrl: string, 
  userContext: UserContextAnalysis, 
  groq: any, 
  addLog: Function
): Promise<ContentAnalysis> {
  try {
    const analysisPrompt = `You are an expert educational content analyst. Analyze this image carefully.

User Context: The student's message suggests they want "${userContext.intent}" (confidence: ${userContext.confidence})
Keywords from user: ${userContext.keywords.join(', ')}

CRITICAL INSTRUCTIONS:
1. First, identify what you actually SEE in the image
2. Don't assume content type based on user context alone
3. Look for actual mathematical symbols, equations, numbers vs. text, letters, words
4. Consider handwriting vs. printed text
5. Note any diagrams, charts, or visual elements

Respond in JSON format:
{
  "contentType": "text|math|science|mixed|unknown",
  "subject": "specific subject detected",
  "confidence": 0.9,
  "hasEquations": false,
  "hasText": true,
  "hasHandwriting": true,
  "textContent": "brief description of visible text",
  "reasoning": "detailed explanation of what you see and why you classified it this way"
}`

    const completion = await callGroqWithRetry(
      groq,
      [
        { role: "system", content: "You are an expert at analyzing educational images and identifying their content type accurately." },
        { 
          role: "user", 
          content: [
            { type: "text", text: analysisPrompt },
            { type: "image_url", image_url: { url: imageUrl } }
          ]
        }
      ],
      "llama3-70b-8192",
      0.05,
      500,
      2,
      addLog
    )

    const result = JSON.parse(completion.choices[0]?.message?.content || '{}')
    
    addLog('IMAGE_ANALYSIS_RESULT', {
      contentType: result.contentType,
      confidence: result.confidence,
      reasoning: result.reasoning?.substring(0, 100) + '...'
    })

    return {
      contentType: result.contentType || 'unknown',
      subject: result.subject || 'g√©n√©ral',
      confidence: result.confidence || 0.5,
      hasEquations: result.hasEquations || false,
      hasText: result.hasText || false,
      hasHandwriting: result.hasHandwriting || false,
      textContent: result.textContent || '',
      reasoning: result.reasoning || 'No analysis available'
    }
  } catch (error) {
    addLog('IMAGE_ANALYSIS_ERROR', { error: error.message }, false)
    return {
      contentType: 'unknown',
      subject: 'g√©n√©ral',
      confidence: 0.3,
      hasEquations: false,
      hasText: true,
      hasHandwriting: false,
      reasoning: 'Analysis failed, using safe defaults'
    }
  }
}

async function generateContextualImageResponse(
  text: string,
  imageUrl: string,
  userContext: UserContextAnalysis,
  contentAnalysis: ContentAnalysis,
  student: any,
  groq: any,
  addLog: Function
): Promise<string> {
  try {
    // Generate content-specific system prompt
    const systemPrompt = generateImageSystemPrompt(student, userContext, contentAnalysis)
    addLog('SYSTEM_PROMPT_GENERATED', { 
      contentType: contentAnalysis.contentType,
      promptLength: systemPrompt.length 
    })

    // Create user message with context
    const userMessage = text ? 
      `${text}\n\n[Image analys√©e - Type d√©tect√©: ${contentAnalysis.contentType}, Confiance: ${contentAnalysis.confidence}]` :
      `Veuillez analyser cette image √©ducative. Type d√©tect√©: ${contentAnalysis.contentType}`

    const completion = await callGroqWithRetry(
      groq,
      [
        { role: "system", content: systemPrompt },
        { 
          role: "user", 
          content: [
            { type: "text", text: userMessage },
            { type: "image_url", image_url: { url: imageUrl } }
          ]
        }
      ],
      "llama3-70b-8192",
      0.7,
      2000,
      3,
      addLog
    )

    const response = completion.choices[0]?.message?.content || 
      "Je suis d√©sol√©, je n'ai pas pu analyser correctement cette image."

    addLog('CONTEXTUAL_RESPONSE_GENERATED', { responseLength: response.length })
    return response

  } catch (error) {
    addLog('CONTEXTUAL_RESPONSE_ERROR', { error: error.message }, false)
    throw error
  }
}

function generateImageSystemPrompt(
  student: any, 
  userContext: UserContextAnalysis, 
  contentAnalysis: ContentAnalysis
): string {
  let basePrompt = `Vous √™tes un assistant √©ducatif sp√©cialis√© pour les √©l√®ves de ${student.level}.

ANALYSE DU CONTENU:
- Type d√©tect√©: ${contentAnalysis.contentType}
- Sujet: ${contentAnalysis.subject}
- Confiance: ${contentAnalysis.confidence}
- Contient des √©quations: ${contentAnalysis.hasEquations ? 'Oui' : 'Non'}
- Contient du texte: ${contentAnalysis.hasText ? 'Oui' : 'Non'}
- √âcriture manuscrite: ${contentAnalysis.hasHandwriting ? 'Oui' : 'Non'}

CONTEXTE UTILISATEUR:
- Intention: ${userContext.intent}
- Mots-cl√©s: ${userContext.keywords.join(', ')}
- Confiance: ${userContext.confidence}`

  // Content-specific instructions
  switch (contentAnalysis.contentType) {
    case 'text':
      basePrompt += `

üî§ CONTENU TEXTUEL D√âTECT√â
Votre r√¥le est d'aider avec:
- Lecture et compr√©hension de textes
- Analyse litt√©raire et interpr√©tation
- Correction grammaticale et orthographique
- Structure d'essais et argumentation
- Compr√©hension linguistique

‚ö†Ô∏è CRITIQUE: Ce contenu semble √™tre du texte/litt√©rature. 
NE cr√©ez PAS d'√©quations math√©matiques ou de formules scientifiques sauf si elles sont clairement visibles dans l'image.
Concentrez-vous sur la langue, l'√©criture et l'analyse litt√©raire.`
      break

    case 'math':
      basePrompt += `

üî¢ CONTENU MATH√âMATIQUE D√âTECT√â
Votre r√¥le est d'aider avec:
- R√©solution de probl√®mes math√©matiques √©tape par √©tape
- Explication de concepts math√©matiques
- Travail sur √©quations et calculs
- Raisonnement math√©matique

‚úÖ Ce contenu contient des math√©matiques. Vous pouvez utiliser des √©quations et des calculs.`
      break

    case 'science':
      basePrompt += `

üî¨ CONTENU SCIENTIFIQUE D√âTECT√â
Votre r√¥le est d'aider avec:
- Explication de concepts scientifiques
- Analyse de probl√®mes et exp√©riences scientifiques
- Compr√©hension de principes scientifiques
- Calculs scientifiques

‚úÖ Ce contenu contient des sciences. Vous pouvez utiliser des formules et des concepts scientifiques.`
      break

    case 'mixed':
      basePrompt += `

üîÄ CONTENU MIXTE D√âTECT√â
Analysez soigneusement l'image et:
- Identifiez clairement les diff√©rents types de contenu
- R√©pondez de mani√®re appropri√©e √† chaque partie
- Soyez explicite sur ce que vous observez
- Adaptez votre aide en cons√©quence`
      break

    default:
      basePrompt += `

‚ùì CONTENU INCERTAIN
- Analysez d'abord soigneusement ce que vous voyez
- Identifiez clairement le type de contenu
- Demandez des clarifications si n√©cessaire
- Ne faites pas d'hypoth√®ses sur le contenu`
  }

  basePrompt += `

INSTRUCTIONS G√âN√âRALES:
- R√©pondez toujours en fran√ßais
- Soyez encourageant et √©ducatif
- Adaptez votre niveau au niveau de l'√©l√®ve (${student.level})
- Si vous n'√™tes pas s√ªr du contenu, demandez des clarifications
- Ne jamais inventer du contenu qui n'est pas visible dans l'image`

  return basePrompt
}

function validateEducationalResponse(
  response: string,
  userContext: UserContextAnalysis,
  contentAnalysis: ContentAnalysis,
  originalText: string,
  addLog: Function
): string {
  addLog('VALIDATION_START', { 
    userIntent: userContext.intent,
    contentType: contentAnalysis.contentType 
  })

  const lowerResponse = response.toLowerCase()
  const lowerText = originalText.toLowerCase()

  // Define indicators
  const mathIndicators = [
    '√©quation', 'equation', 'x =', 'y =', 'f(x)', 'calcul', 'r√©soudre',
    'formule', 'formula', 'd√©riv√©e', 'int√©grale', 'cos(', 'sin(', 'tan(',
    'variable', 'fonction', 'graphique'
  ]

  const textIndicators = [
    'lettre', 'letter', 'dissertation', 'essay', 'texte', 'r√©daction',
    'paragraphe', 'composition', 'r√©cit', 'story', 'po√®me', 'poem',
    'analyse litt√©raire', 'fran√ßais', 'litt√©rature', 'grammaire'
  ]

  const hasMathInResponse = mathIndicators.some(term => lowerResponse.includes(term))
  const userWantsTextHelp = (
    userContext.intent === 'text_help' ||
    textIndicators.some(term => lowerText.includes(term)) ||
    contentAnalysis.contentType === 'text'
  )

  // Detect potential hallucination
  const isPotentialHallucination = (
    userWantsTextHelp && 
    hasMathInResponse && 
    !contentAnalysis.hasEquations &&
    contentAnalysis.confidence > 0.6
  )

  if (isPotentialHallucination) {
    addLog('HALLUCINATION_DETECTED', { 
      userIntent: userContext.intent,
      contentType: contentAnalysis.contentType,
      hasMathInResponse 
    }, false, 'Math content in text response')

    const clarificationPrompt = `

üö® **Attention - V√©rification n√©cessaire**

Il semble que votre image contienne du texte ou de la litt√©rature, mais ma r√©ponse mentionne des √©l√©ments math√©matiques.

**Veuillez pr√©ciser le type de contenu**:
üìù S'agit-il d'une lettre, dissertation, r√©daction ou texte litt√©raire ?
üî¢ Ou contient-elle r√©ellement des √©quations math√©matiques ?

**Type d'aide souhait√©**:
- ‚úèÔ∏è Correction orthographique/grammaticale
- üìñ Analyse litt√©raire ou stylistique  
- ‚úçÔ∏è Aide √† la r√©daction
- üßÆ Explication d'un concept math√©matique

Cela m'aidera √† vous donner une r√©ponse plus pr√©cise et adapt√©e √† votre besoin r√©el.`

    return response + clarificationPrompt
  }

  // Add confidence warning for low-confidence analysis
  if (contentAnalysis.confidence < 0.6) {
    addLog('LOW_CONFIDENCE_WARNING', { confidence: contentAnalysis.confidence })
    
    const uncertaintyNote = `

ü§î **Note de confiance**: Mon analyse de l'image n'est pas totalement certaine (${(contentAnalysis.confidence * 100).toFixed(0)}% de confiance). 

Si ma r√©ponse ne correspond pas au contenu de votre image, n'h√©sitez pas √† me corriger et √† pr√©ciser:
- Le type de document (lettre, exercice, dissertation, etc.)
- La mati√®re concern√©e
- Le type d'aide souhait√©`

    return response + uncertaintyNote
  }

  addLog('VALIDATION_COMPLETE', { 
    hallucinationDetected: false,
    confidenceOk: contentAnalysis.confidence >= 0.6 
  })

  return response
}

function generateTextSystemPrompt(student: any, userContext: UserContextAnalysis): string {
  let prompt = `Vous √™tes un assistant √©ducatif pour les √©l√®ves de ${student.level}.

CONTEXTE UTILISATEUR:
- Intention d√©tect√©e: ${userContext.intent}
- Confiance: ${userContext.confidence}
- Mots-cl√©s: ${userContext.keywords.join(', ')}`

  switch (userContext.intent) {
    case 'text_help':
      prompt += `

Vous aidez avec du contenu textuel/litt√©raire:
- Analyse et compr√©hension de textes
- Correction grammaticale et orthographique
- Structure d'√©criture et argumentation
- Analyse litt√©raire`
      break

    case 'math_help':
      prompt += `

Vous aidez avec des math√©matiques:
- R√©solution de probl√®mes √©tape par √©tape
- Explication de concepts math√©matiques
- Calculs et √©quations`
      break

    case 'science_help':
      prompt += `

Vous aidez avec les sciences:
- Concepts scientifiques
- Exp√©riences et observations
- Calculs scientifiques`
      break

    default:
      prompt += `

Aide g√©n√©rale - adaptez-vous au contenu de la question:
- Identifiez d'abord le type de contenu
- R√©pondez de mani√®re appropri√©e
- Demandez des clarifications si n√©cessaire`
  }

  prompt += `

R√©pondez toujours en fran√ßais, soyez encourageant et √©ducatif.`

  return prompt
}

async function generateBasicEducationalResponse(
  text: string,
  student: any,
  groqConfig: any,
  addLog: Function
): Promise<string> {
  try {
    addLog('BASIC_RESPONSE_START', { textLength: text.length })
    
    const groq = await createGroqClient(groqConfig.userId)
    
    const completion = await callGroqWithRetry(
      groq,
      [
        {
          role: "system",
          content: `Vous √™tes un assistant √©ducatif pour les √©l√®ves de ${student.level}. 
          Aidez l'√©tudiant avec sa question de mani√®re claire et encourageante.
          R√©pondez toujours en fran√ßais.`
        },
        { role: "user", content: text }
      ],
      groqConfig.model,
      0.7,
      1500,
      3,
      addLog
    )

    const response = completion.choices[0]?.message?.content || 
      "Je suis d√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse appropri√©e √† votre question."

    addLog('BASIC_RESPONSE_SUCCESS', { responseLength: response.length })
    return response

  } catch (error) {
    addLog('BASIC_RESPONSE_ERROR', { error: error.message }, false)
    return "Je rencontre des difficult√©s pour traiter votre question. Pourriez-vous la reformuler ou √™tre plus sp√©cifique ?"
  }
}

async function handleClientMessage(
  userIdentifier: string,
  source: string,
  text: string | undefined,
  sessionId: string | undefined,
  userAgent: string | undefined,
  processingLogs: ProcessingLog[],
  addLog: Function
): Promise<string> {
  try {
    const groq = await getSystemGroqClient()
    
    const completion = await callGroqWithRetry(
      groq,
      [
        {
          role: "system",
          content: `Vous √™tes un assistant de service client pour une entreprise de t√©l√©communications.
          Votre objectif est d'aider les clients avec leurs demandes, probl√®mes et questions.
          Soyez professionnel, courtois et orient√© solution.
          ${source === 'web' ? 'L\'utilisateur vous contacte via votre site web.' : 'L\'utilisateur vous contacte via WhatsApp.'}`
        },
        { role: "user", content: text || 'Demande d\'assistance' }
      ],
      "llama3-70b-8192",
      0.7,
      1500,
      3,
      addLog
    )

    const response = completion.choices[0]?.message?.content || 
      "Je suis d√©sol√©, je n'ai pas pu traiter votre demande. Un agent vous contactera bient√¥t."

    // Save conversation
    await saveClientConversation(userIdentifier, source, text, response, sessionId, userAgent, addLog)

    return response

  } catch (error) {
    addLog('CLIENT_ERROR', { error: error.message, source }, false)
    if (source === 'web') {
      return "Merci pour votre message. Notre √©quipe du service client vous r√©pondra dans les plus brefs d√©lais."
    } else {
      return "Merci pour votre message. Un agent du service client vous r√©pondra dans les plus brefs d√©lais."
    }
  }
}

async function handleQuizMessage(
  userIdentifier: string,
  source: string,
  text: string | undefined,
  sessionId: string | undefined,
  userAgent: string | undefined,
  processingLogs: ProcessingLog[],
  addLog: Function
): Promise<string> {
  try {
    const groq = await getSystemGroqClient()
    
    const completion = await callGroqWithRetry(
      groq,
      [
        {
          role: "system",
          content: `Vous √™tes un ma√Ætre de quiz qui cr√©e des quiz √©ducatifs engageants.
          Votre objectif est de rendre l'apprentissage amusant gr√¢ce √† des questions et d√©fis interactifs.
          Soyez enthousiaste, encourageant et fournissez des commentaires informatifs.
          ${source === 'web' ? 'L\'utilisateur participe via votre site web.' : 'L\'utilisateur participe via WhatsApp.'}`
        },
        { role: "user", content: text || 'Commencer le quiz' }
      ],
      "llama3-70b-8192",
      0.7,
      1500,
      3,
      addLog
    )

    const response = completion.choices[0]?.message?.content || 
      "Bienvenue au quiz ! √ätes-vous pr√™t √† tester vos connaissances ?"

    // Save conversation
    await saveQuizConversation(userIdentifier, source, text, response, sessionId, userAgent, addLog)

    return response

  } catch (error) {
    addLog('QUIZ_ERROR', { error: error.message, source }, false)
    return "Bienvenue au quiz ! Posez-moi une question ou demandez un d√©fi."
  }
}

async function getOrCreateStudentProfile(phoneNumber: string, supabase: any, addLog: Function) {
  try {
    // Check if student exists
    const { data: existingStudent } = await supabase
      .from('student_profiles')
      .select('*')
      .eq('phone_number', phoneNumber)
      .maybeSingle()

    if (existingStudent) {
      // Update last active timestamp
      await supabase
        .from('student_profiles')
        .update({ last_active_at: new Date().toISOString() })
        .eq('id', existingStudent.id)

      return existingStudent
    }

    // Create new student profile
    const { data: newStudent, error } = await supabase
      .from('student_profiles')
      .insert({
        phone_number: phoneNumber,
        level: '3√®me',
        subjects: [],
        preferred_language: 'french'
      })
      .select()
      .single()

    if (error) throw error
    return newStudent

  } catch (error) {
    addLog('STUDENT_PROFILE_ERROR', { error: error.message }, false)
    throw error
  }
}

async function getOrCreateEducationSession(studentId: string, supabase: any, addLog: Function) {
  try {
    // Check for active session
    const { data: activeSession } = await supabase
      .from('education_sessions')
      .select('*')
      .eq('student_id', studentId)
      .is('end_time', null)
      .maybeSingle()

    if (activeSession) {
      return activeSession
    }

    // Create new session
    const { data: newSession, error } = await supabase
      .from('education_sessions')
      .insert({
        student_id: studentId,
        subject: 'g√©n√©ral',
        start_time: new Date().toISOString()
      })
      .select()
      .single()

    if (error) throw error
    return newSession

  } catch (error) {
    addLog('EDUCATION_SESSION_ERROR', { error: error.message }, false)
    throw error
  }
}

async function getGroqConfigForEducation(student: any, supabase: any, addLog: Function) {
  try {
    // Try to get user_id from student profile
    let userId = student.user_id

    if (!userId && student.source !== 'web') {
      // Try to get from profils_utilisateurs
      const { data: userProfile } = await supabase
        .from('profils_utilisateurs')
        .select('id')
        .eq('phone_number', student.phone_number)
        .maybeSingle()

      if (userProfile) {
        userId = userProfile.id
      }
    }

    if (!userId) {
      // Get any available Groq config as fallback
      const { data: anyConfig } = await supabase
        .from('user_groq_config')
        .select('user_id, api_key, model')
        .order('updated_at', { ascending: false })
        .limit(1)
        .maybeSingle()

      if (anyConfig) {
        return {
          userId: anyConfig.user_id,
          apiKey: anyConfig.api_key,
          model: anyConfig.model || 'llama3-70b-8192'
        }
      }

      throw new Error('No Groq configuration found')
    }

    // Get user's specific config
    const { data: userConfig } = await supabase
      .from('user_groq_config')
      .select('*')
      .eq('user_id', userId)
      .maybeSingle()

    if (userConfig) {
      return {
        userId: userId,
        apiKey: userConfig.api_key,
        model: userConfig.model || 'llama3-70b-8192'
      }
    }

    throw new Error('No Groq configuration found for user')

  } catch (error) {
    addLog('GROQ_CONFIG_ERROR', { error: error.message }, false)
    throw error
  }
}

async function saveEducationConversation(
  userIdentifier: string,
  source: string,
  userMessage: string | undefined,
  botResponse: string,
  sessionId: string | undefined,
  userAgent: string | undefined,
  supabase: any,
  addLog: Function
) {
  try {
    // Save user message if provided
    if (userMessage) {
      await supabase
        .from('customer_conversations')
        .insert({
          phone_number: source === 'whatsapp' ? userIdentifier : null,
          web_user_id: source === 'web' ? userIdentifier : null,
          session_id: sessionId,
          source: source,
          content: userMessage,
          sender: 'user',
          intent: 'education',
          user_agent: userAgent,
          created_at: new Date().toISOString()
        })
    }

    // Save bot response
    await supabase
      .from('customer_conversations')
      .insert({
        phone_number: source === 'whatsapp' ? userIdentifier : null,
        web_user_id: source === 'web' ? userIdentifier : null,
        session_id: sessionId,
        source: source,
        content: botResponse,
        sender: 'bot',
        intent: 'education',
        user_agent: userAgent,
        created_at: new Date().toISOString()
      })

    addLog('CONVERSATION_SAVED', { 
      userIdentifier,
      source,
      responseLength: botResponse.length 
    })

  } catch (error) {
    addLog('CONVERSATION_SAVE_ERROR', { error: error.message }, false)
    // Don't throw - this is not critical for the response
    console.error('‚ùå [EDUCATION] Failed to save conversation:', error)
  }
}

async function saveClientConversation(
  userIdentifier: string,
  source: string,
  userMessage: string | undefined,
  botResponse: string,
  sessionId: string | undefined,
  userAgent: string | undefined,
  addLog: Function
) {
  try {
    const supabaseUrl = Deno.env.get('SUPABASE_URL')
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
    const supabase = createClient(supabaseUrl!, supabaseServiceKey!)

    // Save user message if provided
    if (userMessage) {
      await supabase
        .from('customer_conversations')
        .insert({
          phone_number: source === 'whatsapp' ? userIdentifier : null,
          web_user_id: source === 'web' ? userIdentifier : null,
          session_id: sessionId,
          source: source,
          content: userMessage,
          sender: 'user',
          intent: 'client',
          user_agent: userAgent,
          created_at: new Date().toISOString()
        })
    }

    // Save bot response
    await supabase
      .from('customer_conversations')
      .insert({
        phone_number: source === 'whatsapp' ? userIdentifier : null,
        web_user_id: source === 'web' ? userIdentifier : null,
        session_id: sessionId,
        source: source,
        content: botResponse,
        sender: 'bot',
        intent: 'client',
        user_agent: userAgent,
        created_at: new Date().toISOString()
      })

    addLog('CLIENT_CONVERSATION_SAVED', { userIdentifier, source })

  } catch (error) {
    addLog('CLIENT_CONVERSATION_SAVE_ERROR', { error: error.message }, false)
    console.error('‚ùå [CLIENT] Failed to save conversation:', error)
  }
}

async function saveQuizConversation(
  userIdentifier: string,
  source: string,
  userMessage: string | undefined,
  botResponse: string,
  sessionId: string | undefined,
  userAgent: string | undefined,
  addLog: Function
) {
  try {
    const supabaseUrl = Deno.env.get('SUPABASE_URL')
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
    const supabase = createClient(supabaseUrl!, supabaseServiceKey!)

    // Save user message if provided
    if (userMessage) {
      await supabase
        .from('customer_conversations')
        .insert({
          phone_number: source === 'whatsapp' ? userIdentifier : null,
          web_user_id: source === 'web' ? userIdentifier : null,
          session_id: sessionId,
          source: source,
          content: userMessage,
          sender: 'user',
          intent: 'quiz',
          user_agent: userAgent,
          created_at: new Date().toISOString()
        })
    }

    // Save bot response
    await supabase
      .from('customer_conversations')
      .insert({
        phone_number: source === 'whatsapp' ? userIdentifier : null,
        web_user_id: source === 'web' ? userIdentifier : null,
        session_id: sessionId,
        source: source,
        content: botResponse,
        sender: 'bot',
        intent: 'quiz',
        user_agent: userAgent,
        created_at: new Date().toISOString()
      })

    addLog('QUIZ_CONVERSATION_SAVED', { userIdentifier, source })

  } catch (error) {
    addLog('QUIZ_CONVERSATION_SAVE_ERROR', { error: error.message }, false)
    console.error('‚ùå [QUIZ] Failed to save conversation:', error)
  }
}